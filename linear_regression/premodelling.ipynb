{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "file_path = '/Users/Pato/Dev/Python/data_temps/ML_Templates/logistic regression/data/log_reg_cleaning.csv'\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "target_variable = 'Attrition'  # Replace with the actual target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Count NaN values per column\n",
    "nans_per_column = data.isna().sum()\n",
    "print(\"NaN values per column:\")\n",
    "print(nans_per_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.T.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "non_numeric_columns = data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "for column in non_numeric_columns:\n",
    "    unique_count = data[column].nunique()\n",
    "    unique_values = data[column].unique()\n",
    "    print(f\"Column '{column}'({unique_count}):{unique_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Binary conversion \n",
    "data['Attrition'] = data['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "data['Gender'] = data['Gender'].map({'Male': 1, 'Female': 0})\n",
    "# data['Over18'] = data['Over18'].map({'Y': 1})  # 'Over18' only has 'Y', so map it to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ordinal encoding \n",
    "data['BusinessTravel'] = data['BusinessTravel'].map({\n",
    "    'Non-Travel': 2, \n",
    "    'Travel_Frequently': 1, \n",
    "    'Travel_Rarely': 0\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding \n",
    "data = pd.get_dummies(data, columns=['JobRole', 'EducationField', 'MaritalStatus', 'Department'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to create buckets based on standard deviations with descriptive labels\n",
    "def create_std_buckets(column, num_buckets=5):\n",
    "    mean = column.mean()\n",
    "    std = column.std()\n",
    "    \n",
    "    # Define the boundaries for the buckets based on standard deviations\n",
    "    bucket_edges = [mean + (i * std) for i in range(-num_buckets // 2, num_buckets // 2 + 1)]\n",
    "    \n",
    "    # Descriptive labels based on standard deviation ranges\n",
    "    if num_buckets == 5:\n",
    "        bucket_labels = [\"Very Low\", \"Low\", \"Average\", \"High\", \"Very High\"]\n",
    "    elif num_buckets == 3:\n",
    "        bucket_labels = [\"Low\", \"Average\", \"High\"]\n",
    "    else:\n",
    "        # Fallback for different number of buckets\n",
    "        bucket_labels = [f\"Bucket {i+1}\" for i in range(len(bucket_edges) - 1)]\n",
    "    \n",
    "    # Cut the column into buckets with descriptive labels\n",
    "    return pd.cut(column, bins=bucket_edges, labels=bucket_labels, include_lowest=True)\n",
    "\n",
    "# List of columns to bucket\n",
    "columns_to_bucket = bin_cols\n",
    "\n",
    "# Apply the bucketing function to the selected columns with descriptive labels\n",
    "for col in columns_to_bucket:\n",
    "    f_data[f'{col}_Bucket'] = create_std_buckets(data[col], num_buckets=5)\n",
    "\n",
    "# Display the first few rows to check the bucket distribution with new labels\n",
    "print(f_data[[f'{col}_Bucket' for col in columns_to_bucket]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "f_data.describe().T"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
